{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b009d150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, '2.8.0+cu128')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available(), torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb5d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b3429ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b21ed202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c031394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tiktoken.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a62ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f72a4e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 11, 995, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14673ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, world!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"Hello, world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42134634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80508ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cu128'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecdeba4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5a765b7290>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1423d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.3823,  0.4150, -0.1171,  0.4593],\n",
       "                      [-0.1096,  0.1009, -0.2434,  0.2936]])),\n",
       "             ('0.bias', tensor([ 0.4408, -0.3668])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.6146,  0.1323],\n",
       "                      [ 0.5224,  0.0958],\n",
       "                      [ 0.3410, -0.0998],\n",
       "                      [ 0.5451,  0.1045]])),\n",
       "             ('2.bias', tensor([-0.3301,  0.1802, -0.3258, -0.0829])),\n",
       "             ('4.weight',\n",
       "              tensor([[-0.2031,  0.3317, -0.3947, -0.2305],\n",
       "                      [-0.1412, -0.3006,  0.0472, -0.4938]])),\n",
       "             ('4.bias', tensor([ 0.4516, -0.4247]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=4, out_features=2, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=2, out_features=4, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=4, out_features=2, bias=True),\n",
    "    nn.Softmax(dim=1),\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46855e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0.weight | Size: torch.Size([2, 4]) | Values : tensor([[ 0.3823,  0.4150, -0.1171,  0.4593],\n",
      "        [-0.1096,  0.1009, -0.2434,  0.2936]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 0.bias | Size: torch.Size([2]) | Values : tensor([ 0.4408, -0.3668], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.weight | Size: torch.Size([4, 2]) | Values : tensor([[0.6146, 0.1323],\n",
      "        [0.5224, 0.0958]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.bias | Size: torch.Size([4]) | Values : tensor([-0.3301,  0.1802], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 4.weight | Size: torch.Size([2, 4]) | Values : tensor([[-0.2031,  0.3317, -0.3947, -0.2305],\n",
      "        [-0.1412, -0.3006,  0.0472, -0.4938]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 4.bias | Size: torch.Size([2]) | Values : tensor([ 0.4516, -0.4247], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68379297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Input: tensor([[ 1.3221,  0.8172, -0.7658, -0.7506]])\n",
      "Output: tensor([[0.8064, 0.1936]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn(1, 4)\n",
    "print(f\"Sample Input: {sample_input}\")\n",
    "output = model(sample_input)\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed5dbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8064, 0.1936]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fe48c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases loaded successfully!\n",
      "Layer 0 weight shape: torch.Size([2, 4])\n",
      "Layer 2 weight shape: torch.Size([4, 2])\n",
      "Layer 4 weight shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Define the weights and biases from the model state_dict\n",
    "# Layer 0 (Linear: 4 -> 2)\n",
    "w0 = torch.tensor(\n",
    "    [[0.1161, 0.2583, 0.0907, -0.1781], [0.2610, 0.2628, 0.1870, -0.0879]]\n",
    ")\n",
    "b0 = torch.tensor([-0.1324, 0.0535])\n",
    "\n",
    "# Layer 2 (Linear: 2 -> 4)\n",
    "w2 = torch.tensor(\n",
    "    [[-0.1249, -0.2107], [0.4520, 0.6077], [-0.0700, -0.1583], [0.0103, -0.0422]]\n",
    ")\n",
    "b2 = torch.tensor([0.1700, 0.1982, -0.6422, -0.2609])\n",
    "\n",
    "# Layer 4 (Linear: 4 -> 2)\n",
    "w4 = torch.tensor(\n",
    "    [[0.4211, 0.1948, -0.0249, -0.3015], [-0.3059, -0.4479, -0.1630, 0.1689]]\n",
    ")\n",
    "b4 = torch.tensor([0.3188, 0.2308])\n",
    "\n",
    "print(\"Weights and biases loaded successfully!\")\n",
    "print(f\"Layer 0 weight shape: {w0.shape}\")\n",
    "print(f\"Layer 2 weight shape: {w2.shape}\")\n",
    "print(f\"Layer 4 weight shape: {w4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3d2f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[ 1.3525,  0.6863, -0.3278,  0.7950]])\n",
      "Input shape: torch.Size([1, 4])\n",
      "\n",
      "After Layer 0 (Linear): tensor([[0.0306, 0.4557]])\n",
      "After ReLU 1: tensor([[0.0306, 0.4557]])\n",
      "After Layer 2 (Linear): tensor([[ 0.0702,  0.4890, -0.7165, -0.2798]])\n",
      "After ReLU 2: tensor([[0.0702, 0.4890, 0.0000, 0.0000]])\n",
      "After Layer 4 (Linear): tensor([[ 0.4436, -0.0097]])\n",
      "Final output (after Softmax): tensor([[0.6114, 0.3886]])\n",
      "\n",
      "Model output for comparison: tensor([[0.8323, 0.1677]], grad_fn=<SoftmaxBackward0>)\n",
      "Outputs match: False\n"
     ]
    }
   ],
   "source": [
    "# Manual forward pass calculation\n",
    "# Using the same input as before\n",
    "sample_input = torch.randn(1, 4)\n",
    "print(f\"Input: {sample_input}\")\n",
    "print(f\"Input shape: {sample_input.shape}\")\n",
    "\n",
    "# Step 1: First linear layer (4 -> 2)\n",
    "z1 = torch.matmul(sample_input, w0.T) + b0\n",
    "print(f\"\\nAfter Layer 0 (Linear): {z1}\")\n",
    "\n",
    "# Step 2: ReLU activation\n",
    "a1 = F.relu(z1)\n",
    "print(f\"After ReLU 1: {a1}\")\n",
    "\n",
    "# Step 3: Second linear layer (2 -> 4)\n",
    "z2 = torch.matmul(a1, w2.T) + b2\n",
    "print(f\"After Layer 2 (Linear): {z2}\")\n",
    "\n",
    "# Step 4: ReLU activation\n",
    "a2 = F.relu(z2)\n",
    "print(f\"After ReLU 2: {a2}\")\n",
    "\n",
    "# Step 5: Third linear layer (4 -> 2)\n",
    "z3 = torch.matmul(a2, w4.T) + b4\n",
    "print(f\"After Layer 4 (Linear): {z3}\")\n",
    "\n",
    "# Step 6: Softmax activation\n",
    "final_output = F.softmax(z3, dim=1)\n",
    "print(f\"Final output (after Softmax): {final_output}\")\n",
    "\n",
    "# Compare with model output\n",
    "model_output = model(sample_input)\n",
    "print(f\"\\nModel output for comparison: {model_output}\")\n",
    "print(f\"Outputs match: {torch.allclose(final_output, model_output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "939b1fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED STEP-BY-STEP CALCULATION ===\n",
      "Input x: tensor([[0.3367, 0.1288, 0.2345, 0.2303]])\n",
      "Input values: [0.3367, 0.1288, 0.2345, 0.2303]\n",
      "\n",
      "--- Layer 0: Linear(4->2) ---\n",
      "Weight matrix W0:\n",
      "tensor([[ 0.1161,  0.2583,  0.0907, -0.1781],\n",
      "        [ 0.2610,  0.2628,  0.1870, -0.0879]])\n",
      "Bias b0: tensor([-0.1324,  0.0535])\n",
      "Calculating z1 manually:\n",
      "value of z1_manual: tensor([[0., 0.]])\n",
      "z1[0] = 0.3367*0.1161 + 0.1288*0.2583 + 0.2345*0.0907 + 0.2303*-0.1781 + -0.1324 = -0.0798\n",
      "z1[1] = 0.3367*0.2610 + 0.1288*0.2628 + 0.2345*0.1870 + 0.2303*-0.0879 + 0.0535 = 0.1988\n",
      "Result z1: tensor([[-0.0798,  0.1988]])\n",
      "\n",
      "--- ReLU Activation ---\n",
      "a1 = ReLU(z1) = tensor([[0.0000, 0.1988]])\n",
      "\n",
      "--- Layer 2: Linear(2->4) ---\n",
      "Weight matrix W2:\n",
      "tensor([[-0.1249, -0.2107],\n",
      "        [ 0.4520,  0.6077],\n",
      "        [-0.0700, -0.1583],\n",
      "        [ 0.0103, -0.0422]])\n",
      "Bias b2: tensor([ 0.1700,  0.1982, -0.6422, -0.2609])\n",
      "z2[0] = 0.0000*-0.1249 + 0.1988*-0.2107 + 0.1700 = 0.1281\n",
      "z2[1] = 0.0000*0.4520 + 0.1988*0.6077 + 0.1982 = 0.3190\n",
      "z2[2] = 0.0000*-0.0700 + 0.1988*-0.1583 + -0.6422 = -0.6737\n",
      "z2[3] = 0.0000*0.0103 + 0.1988*-0.0422 + -0.2609 = -0.2693\n",
      "Result z2: tensor([[ 0.1281,  0.3190, -0.6737, -0.2693]])\n",
      "\n",
      "--- ReLU Activation ---\n",
      "a2 = ReLU(z2) = tensor([[0.1281, 0.3190, 0.0000, 0.0000]])\n",
      "\n",
      "--- Layer 4: Linear(4->2) ---\n",
      "Weight matrix W4:\n",
      "tensor([[ 0.4211,  0.1948, -0.0249, -0.3015],\n",
      "        [-0.3059, -0.4479, -0.1630,  0.1689]])\n",
      "Bias b4: tensor([0.3188, 0.2308])\n",
      "z3[0] = 0.1281*0.4211 + 0.3190*0.1948 + 0.0000*-0.0249 + 0.0000*-0.3015 + 0.3188 = 0.4349\n",
      "z3[1] = 0.1281*-0.3059 + 0.3190*-0.4479 + 0.0000*-0.1630 + 0.0000*0.1689 + 0.2308 = 0.0487\n",
      "Result z3: tensor([[0.4349, 0.0487]])\n",
      "\n",
      "--- Softmax Activation ---\n",
      "Softmax calculation:\n",
      "exp(z3): tensor([[1.5448, 1.0499]])\n",
      "Sum of exp: 2.5947232246398926\n",
      "Final output: tensor([[0.5954, 0.4046]])\n",
      "\n",
      "=== VERIFICATION ===\n",
      "Model output: tensor([[0.7849, 0.2151]], grad_fn=<SoftmaxBackward0>)\n",
      "Manual calculation matches model: False\n"
     ]
    }
   ],
   "source": [
    "# Detailed step-by-step calculation showing matrix operations\n",
    "print(\"=== DETAILED STEP-BY-STEP CALCULATION ===\")\n",
    "\n",
    "# Reset to get the same input\n",
    "torch.manual_seed(42)\n",
    "x = torch.randn(1, 4)\n",
    "print(f\"Input x: {x}\")\n",
    "print(f\"Input values: [{x[0, 0]:.4f}, {x[0, 1]:.4f}, {x[0, 2]:.4f}, {x[0, 3]:.4f}]\")\n",
    "\n",
    "print(\"\\n--- Layer 0: Linear(4->2) ---\")\n",
    "print(f\"Weight matrix W0:\\n{w0}\")\n",
    "print(f\"Bias b0: {b0}\")\n",
    "\n",
    "# # Manual matrix multiplication for first layer\n",
    "z1_manual = torch.zeros(1, 2)\n",
    "print(f\"Calculating z1 manually:\\nvalue of z1_manual: {z1_manual}\")\n",
    "for i in range(2):\n",
    "    z1_manual[0, i] = sum(x[0, j] * w0[i, j] for j in range(4)) + b0[i]\n",
    "    print(\n",
    "        f\"z1[{i}] = {' + '.join([f'{x[0, j]:.4f}*{w0[i, j]:.4f}' for j in range(4)])} + {b0[i]:.4f} = {z1_manual[0, i]:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Result z1: {z1_manual}\")\n",
    "\n",
    "print(\"\\n--- ReLU Activation ---\")\n",
    "a1 = F.relu(z1_manual)\n",
    "print(f\"a1 = ReLU(z1) = {a1}\")\n",
    "\n",
    "print(\"\\n--- Layer 2: Linear(2->4) ---\")\n",
    "print(f\"Weight matrix W2:\\n{w2}\")\n",
    "print(f\"Bias b2: {b2}\")\n",
    "\n",
    "# Manual calculation for second layer\n",
    "z2_manual = torch.zeros(1, 4)\n",
    "for i in range(4):  # output features\n",
    "    z2_manual[0, i] = sum(a1[0, j] * w2[i, j] for j in range(2)) + b2[i]\n",
    "    print(\n",
    "        f\"z2[{i}] = {' + '.join([f'{a1[0, j]:.4f}*{w2[i, j]:.4f}' for j in range(2)])} + {b2[i]:.4f} = {z2_manual[0, i]:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Result z2: {z2_manual}\")\n",
    "\n",
    "print(\"\\n--- ReLU Activation ---\")\n",
    "a2 = F.relu(z2_manual)\n",
    "print(f\"a2 = ReLU(z2) = {a2}\")\n",
    "\n",
    "print(\"\\n--- Layer 4: Linear(4->2) ---\")\n",
    "print(f\"Weight matrix W4:\\n{w4}\")\n",
    "print(f\"Bias b4: {b4}\")\n",
    "\n",
    "# Manual calculation for third layer\n",
    "z3_manual = torch.zeros(1, 2)\n",
    "for i in range(2):  # output features\n",
    "    z3_manual[0, i] = sum(a2[0, j] * w4[i, j] for j in range(4)) + b4[i]\n",
    "    print(\n",
    "        f\"z3[{i}] = {' + '.join([f'{a2[0, j]:.4f}*{w4[i, j]:.4f}' for j in range(4)])} + {b4[i]:.4f} = {z3_manual[0, i]:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Result z3: {z3_manual}\")\n",
    "\n",
    "print(\"\\n--- Softmax Activation ---\")\n",
    "final_manual = F.softmax(z3_manual, dim=1)\n",
    "print(\"Softmax calculation:\")\n",
    "print(f\"exp(z3): {torch.exp(z3_manual)}\")\n",
    "print(f\"Sum of exp: {torch.sum(torch.exp(z3_manual))}\")\n",
    "print(f\"Final output: {final_manual}\")\n",
    "\n",
    "print(\"\\n=== VERIFICATION ===\")\n",
    "model_out = model(x)\n",
    "print(f\"Model output: {model_out}\")\n",
    "print(f\"Manual calculation matches model: {torch.allclose(final_manual, model_out)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2cbde88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "torch.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2426ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90835e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cdee599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7af80e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00b09cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cf56cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67ba720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6983, -0.2393,  0.4663,  ..., -0.2332, -1.6942, -0.4870],\n",
       "        [-0.2647,  1.0030, -0.7152,  ..., -2.1470, -3.9652,  1.0154],\n",
       "        [-0.0852, -0.3196, -0.0370,  ..., -0.2633,  1.2498, -0.5878],\n",
       "        ...,\n",
       "        [ 0.4418, -1.4664,  0.4245,  ..., -0.7113,  0.8049, -0.3494],\n",
       "        [-0.7226,  0.7954, -0.4126,  ..., -0.1578, -0.1787,  1.0665],\n",
       "        [-2.5271, -0.0612,  0.2549,  ...,  0.2055,  1.0083,  0.0092]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37a66b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c660b400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-13.8330,  -5.3112,  -7.5985,  ...,   8.2144,  14.9718, -10.1256],\n",
       "        [ 17.5398, -27.5295,   5.2320,  ...,  10.1908,  -8.4034, -22.6903],\n",
       "        [-23.7189,   3.9519,  -5.0085,  ..., -27.2681,  -0.3879,  -8.4894],\n",
       "        ...,\n",
       "        [ -3.3674,  -2.2970,  -9.4482,  ...,  20.2985,   3.7605, -22.7935],\n",
       "        [  0.7842,   9.7126,   5.1600,  ..., -23.8131, -10.6342,  -5.6311],\n",
       "        [ 13.5285,  -6.0289,  16.0532,  ...,   1.8206,  -3.6772,  -8.3824]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da81fbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 128]), torch.Size([128, 256]), torch.Size([100, 256]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, W.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b8376eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48b04f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05666832, 0.93189054, 0.01144114])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "logits = np.array([2.3, 5.1, 0.7])\n",
    "exps = np.exp(logits)\n",
    "probs = exps / np.sum(exps)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84e204ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05666832, 0.93189054, 0.01144114])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = exps / np.sum(exps)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c1ce74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_logits = logits - np.max(logits)\n",
    "stable_exps = np.exp(stable_logits)\n",
    "softmax = stable_exps / np.sum(stable_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8255f330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05666832, 0.93189054, 0.01144114])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47ccbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([2.3, 5.1, 0.7])\n",
    "softmax = torch.nn.functional.softmax(logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c2b563d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0567, 0.9319, 0.0114])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30dc4b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_logits = torch.tensor([[2.3, 5.1, 0.7], [1.2, 0.4, 3.3], [0.5, 2.2, 1.1]])\n",
    "probs = torch.nn.functional.softmax(batch_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8e3e389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0567, 0.9319, 0.0114],\n",
       "        [0.1040, 0.0467, 0.8493],\n",
       "        [0.1205, 0.6598, 0.2196]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4d0c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=10, out_features=10)\n",
    "\n",
    "        self.register_buffer(\"scale\", torch.tensor(0.5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) * self.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f73df55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear.weight | Size: torch.Size([10, 10]) | Values : tensor([[ 0.1070, -0.0232, -0.2667, -0.2575, -0.2214,  0.1837,  0.1073,  0.2075,\n",
      "          0.2756, -0.0211],\n",
      "        [ 0.0510, -0.0828, -0.2874, -0.0333,  0.2906,  0.0826,  0.1578, -0.1425,\n",
      "         -0.0587,  0.2346]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear.bias | Size: torch.Size([10]) | Values : tensor([-0.2396, -0.1796], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07e348a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('scale', tensor(0.5000)),\n",
       "             ('linear.weight',\n",
       "              tensor([[ 0.1070, -0.0232, -0.2667, -0.2575, -0.2214,  0.1837,  0.1073,  0.2075,\n",
       "                        0.2756, -0.0211],\n",
       "                      [ 0.0510, -0.0828, -0.2874, -0.0333,  0.2906,  0.0826,  0.1578, -0.1425,\n",
       "                       -0.0587,  0.2346],\n",
       "                      [-0.0279, -0.0582,  0.0089,  0.0809, -0.2207,  0.1618,  0.1365, -0.2807,\n",
       "                        0.0756, -0.0237],\n",
       "                      [ 0.0247,  0.0117,  0.2996, -0.1506,  0.0739,  0.2382,  0.3152, -0.3021,\n",
       "                       -0.2451, -0.1656],\n",
       "                      [ 0.0078,  0.1948,  0.0744,  0.1331, -0.2599,  0.2712, -0.1850, -0.0853,\n",
       "                        0.0919, -0.2560],\n",
       "                      [ 0.1144,  0.1566, -0.0552, -0.0942,  0.2662, -0.1962, -0.1821,  0.2237,\n",
       "                        0.2415,  0.0334],\n",
       "                      [ 0.0136,  0.0875, -0.2845,  0.1681,  0.0534, -0.1410, -0.2750, -0.0830,\n",
       "                       -0.0067,  0.1642],\n",
       "                      [ 0.2144,  0.2413,  0.0885, -0.0233, -0.1321,  0.2405,  0.3002, -0.2680,\n",
       "                       -0.1261,  0.3057],\n",
       "                      [ 0.1056, -0.1681,  0.0996, -0.0427,  0.2555, -0.3131, -0.0517, -0.2045,\n",
       "                       -0.2941, -0.2916],\n",
       "                      [ 0.2764, -0.2954, -0.2707,  0.2164, -0.1141,  0.2594,  0.2970, -0.1689,\n",
       "                       -0.1371,  0.0469]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.2396, -0.1796,  0.2167, -0.0927,  0.0965, -0.0780, -0.1230,  0.0126,\n",
       "                      -0.0999,  0.3143]))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba093d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['scale', 'linear.weight', 'linear.bias'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff67b0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer: scale | Size: torch.Size([]) | Values : 0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, buf in model.named_buffers():\n",
    "    print(f\"Buffer: {name} | Size: {buf.size()} | Values : {buf} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7f80ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67485f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = nn.BatchNorm1d(num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e3f5b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer: running_mean | Size: torch.Size([10]) | Values : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Buffer: running_var | Size: torch.Size([10]) | Values : tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Buffer: num_batches_tracked | Size: torch.Size([]) | Values : 0\n"
     ]
    }
   ],
   "source": [
    "for name, buf in bn.named_buffers():\n",
    "    print(f\"Buffer: {name} | Size: {buf.size()} | Values : {buf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7793eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('num_batches_tracked', tensor(0))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f8944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
